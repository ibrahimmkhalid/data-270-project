{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0089b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ibrahim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ibrahim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ibrahim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abc39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"baseline\"\n",
    "stem = \"stem\"\n",
    "lem = \"lem\"\n",
    "bow = \"bow\"\n",
    "tfidf = \"tfidf\"\n",
    "random_state = 42\n",
    "testing_n = 5000\n",
    "large_n = 50000\n",
    "random.seed(random_state)\n",
    "data_path = \"./data/combined.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04205b52",
   "metadata": {},
   "source": [
    "# EDA and simple preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659411f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall            0.000000\n",
      "verified           0.000000\n",
      "reviewTime         0.000000\n",
      "reviewerID         0.000000\n",
      "asin               0.000000\n",
      "style             50.710965\n",
      "reviewerName       0.016280\n",
      "reviewText         0.049506\n",
      "summary            0.025620\n",
      "unixReviewTime     0.000000\n",
      "vote              84.972458\n",
      "image             97.894193\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "print(df.isna().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91610b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall                0\n",
      "verified               0\n",
      "reviewTime             0\n",
      "reviewerID             0\n",
      "asin                   0\n",
      "style             380030\n",
      "reviewerName         122\n",
      "reviewText           371\n",
      "summary              192\n",
      "unixReviewTime         0\n",
      "vote              636787\n",
      "image             733623\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed7e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.47241852636673\n"
     ]
    }
   ],
   "source": [
    "shpae = df.shape\n",
    "print(df.isna().sum().sum() / (shpae[0] * shpae[1]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c344f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 1, 2016</td>\n",
       "      <td>A3CIUOJXQ5VDQ2</td>\n",
       "      <td>B0000530HU</td>\n",
       "      <td>{'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...</td>\n",
       "      <td>Shelly F</td>\n",
       "      <td>As advertised. Reasonably priced</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1472688000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11 14, 2013</td>\n",
       "      <td>A3H7T87S984REU</td>\n",
       "      <td>B0000530HU</td>\n",
       "      <td>{'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...</td>\n",
       "      <td>houserules18</td>\n",
       "      <td>Like the oder and the feel when I put it on my...</td>\n",
       "      <td>Good for the face</td>\n",
       "      <td>1384387200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 18, 2013</td>\n",
       "      <td>A3J034YH7UG4KT</td>\n",
       "      <td>B0000530HU</td>\n",
       "      <td>{'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>I bought this to smell nice after I shave.  Wh...</td>\n",
       "      <td>Smells awful</td>\n",
       "      <td>1376784000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>05 3, 2011</td>\n",
       "      <td>A2UEO5XR3598GI</td>\n",
       "      <td>B0000530HU</td>\n",
       "      <td>{'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...</td>\n",
       "      <td>Rich K</td>\n",
       "      <td>HEY!! I am an Aqua Velva Man and absolutely lo...</td>\n",
       "      <td>Truth is There IS Nothing Like an AQUA VELVA MAN.</td>\n",
       "      <td>1304380800</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 6, 2011</td>\n",
       "      <td>A3SFRT223XXWF7</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>{'Size:': ' 200ml/6.7oz'}</td>\n",
       "      <td>C. C. Christian</td>\n",
       "      <td>If you ever want to feel pampered by a shampoo...</td>\n",
       "      <td>Bvlgari Shampoo</td>\n",
       "      <td>1304640000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True   09 1, 2016  A3CIUOJXQ5VDQ2  B0000530HU   \n",
       "1      5.0      True  11 14, 2013  A3H7T87S984REU  B0000530HU   \n",
       "2      1.0      True  08 18, 2013  A3J034YH7UG4KT  B0000530HU   \n",
       "3      5.0     False   05 3, 2011  A2UEO5XR3598GI  B0000530HU   \n",
       "4      5.0      True   05 6, 2011  A3SFRT223XXWF7  B00006L9LC   \n",
       "\n",
       "                                               style     reviewerName  \\\n",
       "0  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...         Shelly F   \n",
       "1  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...     houserules18   \n",
       "2  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...             Adam   \n",
       "3  {'Size:': ' 7.0 oz', 'Flavor:': ' Classic Ice ...           Rich K   \n",
       "4                          {'Size:': ' 200ml/6.7oz'}  C. C. Christian   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0                   As advertised. Reasonably priced   \n",
       "1  Like the oder and the feel when I put it on my...   \n",
       "2  I bought this to smell nice after I shave.  Wh...   \n",
       "3  HEY!! I am an Aqua Velva Man and absolutely lo...   \n",
       "4  If you ever want to feel pampered by a shampoo...   \n",
       "\n",
       "                                             summary  unixReviewTime vote  \\\n",
       "0                                         Five Stars      1472688000  NaN   \n",
       "1                                  Good for the face      1384387200  NaN   \n",
       "2                                       Smells awful      1376784000  NaN   \n",
       "3  Truth is There IS Nothing Like an AQUA VELVA MAN.      1304380800   25   \n",
       "4                                    Bvlgari Shampoo      1304640000    3   \n",
       "\n",
       "  image  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8cb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"overall\", \"reviewText\", \"summary\", \"verified\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8406fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall       0.000000\n",
      "reviewText    0.049506\n",
      "summary       0.025620\n",
      "verified      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44456fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba2c603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall       0.0\n",
      "reviewText    0.0\n",
      "summary       0.0\n",
      "verified      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3321b122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>verified</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviewTextWithSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As advertised. Reasonably priced</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars As advertised. Reasonably priced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Like the oder and the feel when I put it on my...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Good for the face Like the oder and the feel w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought this to smell nice after I shave.  Wh...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Smells awful I bought this to smell nice after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEY!! I am an Aqua Velva Man and absolutely lo...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Truth is There IS Nothing Like an AQUA VELVA M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you ever want to feel pampered by a shampoo...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Bvlgari Shampoo If you ever want to feel pampe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  verified  sentiment  \\\n",
       "0                   As advertised. Reasonably priced      True          1   \n",
       "1  Like the oder and the feel when I put it on my...      True          1   \n",
       "2  I bought this to smell nice after I shave.  Wh...      True         -1   \n",
       "3  HEY!! I am an Aqua Velva Man and absolutely lo...     False          1   \n",
       "4  If you ever want to feel pampered by a shampoo...      True          1   \n",
       "\n",
       "                               reviewTextWithSummary  \n",
       "0        Five Stars As advertised. Reasonably priced  \n",
       "1  Good for the face Like the oder and the feel w...  \n",
       "2  Smells awful I bought this to smell nice after...  \n",
       "3  Truth is There IS Nothing Like an AQUA VELVA M...  \n",
       "4  Bvlgari Shampoo If you ever want to feel pampe...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"] = df[\"overall\"].apply(lambda x: 1 if x > 3 else -1 if x < 3 else 0)\n",
    "df[\"reviewTextWithSummary\"] = df[\"summary\"] + \" \" + df[\"reviewText\"]\n",
    "df.drop([\"overall\", \"summary\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fbace13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       " 1    657241\n",
       " 0     47109\n",
       "-1     44501\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd5e0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>verified</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviewTextWithSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As advertised. Reasonably priced</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars As advertised. Reasonably priced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Like the oder and the feel when I put it on my...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Good for the face Like the oder and the feel w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought this to smell nice after I shave.  Wh...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Smells awful I bought this to smell nice after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEY!! I am an Aqua Velva Man and absolutely lo...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Truth is There IS Nothing Like an AQUA VELVA M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you ever want to feel pampered by a shampoo...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Bvlgari Shampoo If you ever want to feel pampe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  verified  sentiment  \\\n",
       "0                   As advertised. Reasonably priced      True          1   \n",
       "1  Like the oder and the feel when I put it on my...      True          1   \n",
       "2  I bought this to smell nice after I shave.  Wh...      True         -1   \n",
       "3  HEY!! I am an Aqua Velva Man and absolutely lo...     False          1   \n",
       "4  If you ever want to feel pampered by a shampoo...      True          1   \n",
       "\n",
       "                               reviewTextWithSummary  \n",
       "0        Five Stars As advertised. Reasonably priced  \n",
       "1  Good for the face Like the oder and the feel w...  \n",
       "2  Smells awful I bought this to smell nice after...  \n",
       "3  Truth is There IS Nothing Like an AQUA VELVA M...  \n",
       "4  Bvlgari Shampoo If you ever want to feel pampe...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0dae5",
   "metadata": {},
   "source": [
    "# Model experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98d2c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "-1    5000\n",
       " 0    5000\n",
       " 1    5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing = (\n",
    "    df.groupby(\"sentiment\")\n",
    "    .apply(lambda x: x.sample(n=testing_n, random_state=random_state, replace=True))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_testing[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128a6242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>verified</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviewTextWithSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intuit is a despicable company now. This is th...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>Intuit is One Unethical Company. Any alternati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very disappointed guitar came damaged with den...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Very disappointed Very disappointed guitar cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The rings did not perform as I had hoped. They...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Not what I was hoping for The rings did not pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My ProFX8 purchased from Amazon in 2015 was po...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>Mine broke. Very light use. Padded case. Maybe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not the greatest, really flimsy.</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Two Stars Not the greatest, really flimsy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  verified  sentiment  \\\n",
       "0  Intuit is a despicable company now. This is th...     False         -1   \n",
       "1  Very disappointed guitar came damaged with den...      True         -1   \n",
       "2  The rings did not perform as I had hoped. They...      True         -1   \n",
       "3  My ProFX8 purchased from Amazon in 2015 was po...     False         -1   \n",
       "4                   Not the greatest, really flimsy.      True         -1   \n",
       "\n",
       "                               reviewTextWithSummary  \n",
       "0  Intuit is One Unethical Company. Any alternati...  \n",
       "1  Very disappointed Very disappointed guitar cam...  \n",
       "2  Not what I was hoping for The rings did not pe...  \n",
       "3  Mine broke. Very light use. Padded case. Maybe...  \n",
       "4         Two Stars Not the greatest, really flimsy.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a2229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 15000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d3a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e24c7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence, stop, type_proc=None):\n",
    "    words = []\n",
    "    for word in sentence.lower().strip().split():\n",
    "\n",
    "        word = re.sub(\"\\d\", \"\", word)\n",
    "        word = re.sub(\"[^\\w\\s]\", \"\", word)\n",
    "\n",
    "        if word not in stop and word != \"\":\n",
    "            words.append(preprocess_type(word, type_proc))\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83b1d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_type(word, type_proc):\n",
    "    if type_proc == baseline:\n",
    "        return word\n",
    "    elif type_proc == stem:\n",
    "        return PorterStemmer().stem(word)\n",
    "    elif type_proc == lem:\n",
    "        return WordNetLemmatizer().lemmatize(word)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Preprocessing Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4dc149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(cols, test_size, df=df, random_state=random_state):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        df[cols], df[\"sentiment\"], test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5f55ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(proc, x_train, x_test):\n",
    "    if proc is None:\n",
    "        return x_train, x_test\n",
    "    cols = x_train.columns\n",
    "\n",
    "    textcol = \"reviewText\"\n",
    "    if \"reviewText\" not in cols and \"reviewTextWithSummary\" in cols:\n",
    "        textcol = \"reviewTextWithSummary\"\n",
    "    x_train[textcol] = x_train[textcol].apply(\n",
    "        lambda x: preprocess_text(x, STOP_WORDS, proc)\n",
    "    )\n",
    "    x_test[textcol] = x_test[textcol].apply(\n",
    "        lambda x: preprocess_text(x, STOP_WORDS, proc)\n",
    "    )\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede20bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col(x, col):\n",
    "    col = np.array([col]).T\n",
    "    return hstack([x, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34142bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(cols, test_size, proc, vectorizer, df=df, random_state=random_state):\n",
    "    if \"reviewText\" not in cols and \"reviewTextWithSummary\" not in cols:\n",
    "        raise ValueError(\"Must contain reviewText or reviewTextWithSummary\")\n",
    "\n",
    "    textcol = \"reviewText\"\n",
    "    if \"reviewText\" not in cols and \"reviewTextWithSummary\" in cols:\n",
    "        textcol = \"reviewTextWithSummary\"\n",
    "    x_train, x_test, y_train, y_test = my_train_test_split(\n",
    "        cols, test_size, df, random_state\n",
    "    )\n",
    "    x_train, x_test = apply_preprocessing(proc, x_train, x_test)\n",
    "    if vectorizer == bow:\n",
    "        vectorizer = CountVectorizer()\n",
    "    elif vectorizer == tfidf:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Vectorizer\")\n",
    "    x_train_ = vectorizer.fit_transform(x_train[textcol])\n",
    "    x_test_ = vectorizer.transform(x_test[textcol])\n",
    "\n",
    "    if \"verified\" in cols:\n",
    "        x_train = add_col(x_train_, x_train[\"verified\"])\n",
    "        x_test = add_col(x_test_, x_test[\"verified\"])\n",
    "    else:\n",
    "        x_train = x_train_\n",
    "        x_test = x_test_\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdca857",
   "metadata": {},
   "source": [
    "## Testing different configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d66ed88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"kernel\": [\"rbf\", \"linear\"],\n",
    "}\n",
    "n_jobs = -1\n",
    "verbose = 0\n",
    "cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127f4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_list = pd.DataFrame(\n",
    "    columns=[\"Grid Params\", \"Data config and preprocessing\", \"Grid Score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd80adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_gen = False\n",
    "col_comb = [\n",
    "    [\"reviewText\"],\n",
    "    [\"reviewText\", \"verified\"],\n",
    "    [\"reviewTextWithSummary\"],\n",
    "    [\"reviewTextWithSummary\", \"verified\"],\n",
    "]\n",
    "proc_comb = [None, baseline, stem, lem]\n",
    "vectorizer_comb = [bow, tfidf]\n",
    "if code_gen:\n",
    "    for col in col_comb:\n",
    "        for proc in proc_comb:\n",
    "            for vectorizer in vectorizer_comb:\n",
    "                params = {\n",
    "                    \"col\": col,\n",
    "                    \"proc\": proc,\n",
    "                    \"vectorizer\": vectorizer,\n",
    "                }\n",
    "                print(\n",
    "                    f\"\"\"\n",
    "# %%\n",
    "x_train, x_test, y_train, y_test = pipeline({col}, 0.25, {proc}, {vectorizer}, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {params}, grid_score]\n",
    "\"\"\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a550869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is code genderated by above cell, to make changes to the code, edit the\n",
    "# above cell and run it, pasting its contents between the markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b3f056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.69      0.71      1284\n",
      "           0       0.60      0.56      0.58      1225\n",
      "           1       0.75      0.84      0.79      1241\n",
      "\n",
      "    accuracy                           0.70      3750\n",
      "   macro avg       0.69      0.70      0.69      3750\n",
      "weighted avg       0.69      0.70      0.69      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####### START OF GENERATED CODE #######\n",
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, None, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': None, 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d301ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.74      0.74      1284\n",
      "           0       0.62      0.64      0.63      1225\n",
      "           1       0.82      0.79      0.80      1241\n",
      "\n",
      "    accuracy                           0.72      3750\n",
      "   macro avg       0.73      0.72      0.73      3750\n",
      "weighted avg       0.73      0.72      0.73      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, None, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': None, 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb4bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.68      0.69      1284\n",
      "           0       0.59      0.54      0.56      1225\n",
      "           1       0.71      0.80      0.75      1241\n",
      "\n",
      "    accuracy                           0.67      3750\n",
      "   macro avg       0.67      0.67      0.67      3750\n",
      "weighted avg       0.67      0.67      0.67      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, baseline, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': 'baseline', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7deb067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.71      0.71      1284\n",
      "           0       0.60      0.63      0.61      1225\n",
      "           1       0.80      0.76      0.78      1241\n",
      "\n",
      "    accuracy                           0.70      3750\n",
      "   macro avg       0.70      0.70      0.70      3750\n",
      "weighted avg       0.70      0.70      0.70      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, baseline, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': 'baseline', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c76e621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.68      0.69      1284\n",
      "           0       0.59      0.56      0.57      1225\n",
      "           1       0.72      0.78      0.75      1241\n",
      "\n",
      "    accuracy                           0.67      3750\n",
      "   macro avg       0.67      0.67      0.67      3750\n",
      "weighted avg       0.67      0.67      0.67      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, stem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': 'stem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca22b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.69      0.70      1284\n",
      "           0       0.59      0.63      0.61      1225\n",
      "           1       0.79      0.75      0.77      1241\n",
      "\n",
      "    accuracy                           0.69      3750\n",
      "   macro avg       0.69      0.69      0.69      3750\n",
      "weighted avg       0.70      0.69      0.69      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, stem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': 'stem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c520556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.64      0.66      1284\n",
      "           0       0.58      0.54      0.56      1225\n",
      "           1       0.71      0.81      0.76      1241\n",
      "\n",
      "    accuracy                           0.66      3750\n",
      "   macro avg       0.66      0.66      0.66      3750\n",
      "weighted avg       0.66      0.66      0.66      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, lem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': 'lem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "460f4959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.70      0.70      1284\n",
      "           0       0.60      0.63      0.61      1225\n",
      "           1       0.79      0.76      0.77      1241\n",
      "\n",
      "    accuracy                           0.69      3750\n",
      "   macro avg       0.70      0.69      0.69      3750\n",
      "weighted avg       0.70      0.69      0.69      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText'], 0.25, lem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText'], 'proc': 'lem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d9a3894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.70      0.71      1284\n",
      "           0       0.61      0.56      0.58      1225\n",
      "           1       0.76      0.83      0.79      1241\n",
      "\n",
      "    accuracy                           0.70      3750\n",
      "   macro avg       0.69      0.70      0.70      3750\n",
      "weighted avg       0.69      0.70      0.70      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, None, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': None, 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d108e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.75      0.74      1284\n",
      "           0       0.62      0.64      0.63      1225\n",
      "           1       0.82      0.78      0.80      1241\n",
      "\n",
      "    accuracy                           0.72      3750\n",
      "   macro avg       0.73      0.72      0.72      3750\n",
      "weighted avg       0.73      0.72      0.72      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, None, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': None, 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20eeeeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.69      0.69      1284\n",
      "           0       0.60      0.56      0.58      1225\n",
      "           1       0.73      0.79      0.76      1241\n",
      "\n",
      "    accuracy                           0.68      3750\n",
      "   macro avg       0.67      0.68      0.67      3750\n",
      "weighted avg       0.67      0.68      0.68      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, baseline, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': 'baseline', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a2ad984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.72      0.71      1284\n",
      "           0       0.59      0.61      0.60      1225\n",
      "           1       0.80      0.75      0.77      1241\n",
      "\n",
      "    accuracy                           0.69      3750\n",
      "   macro avg       0.70      0.69      0.70      3750\n",
      "weighted avg       0.70      0.69      0.70      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, baseline, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': 'baseline', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7cdad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.68      0.69      1284\n",
      "           0       0.59      0.56      0.57      1225\n",
      "           1       0.73      0.78      0.76      1241\n",
      "\n",
      "    accuracy                           0.67      3750\n",
      "   macro avg       0.67      0.67      0.67      3750\n",
      "weighted avg       0.67      0.67      0.67      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, stem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': 'stem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "464fb3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.70      0.70      1284\n",
      "           0       0.59      0.63      0.61      1225\n",
      "           1       0.80      0.74      0.77      1241\n",
      "\n",
      "    accuracy                           0.69      3750\n",
      "   macro avg       0.69      0.69      0.69      3750\n",
      "weighted avg       0.70      0.69      0.69      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, stem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': 'stem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b513fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.67      0.67      1284\n",
      "           0       0.59      0.54      0.56      1225\n",
      "           1       0.72      0.79      0.75      1241\n",
      "\n",
      "    accuracy                           0.67      3750\n",
      "   macro avg       0.66      0.67      0.66      3750\n",
      "weighted avg       0.66      0.67      0.66      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, lem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': 'lem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb92ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.71      0.70      1284\n",
      "           0       0.59      0.62      0.60      1225\n",
      "           1       0.79      0.75      0.77      1241\n",
      "\n",
      "    accuracy                           0.69      3750\n",
      "   macro avg       0.69      0.69      0.69      3750\n",
      "weighted avg       0.69      0.69      0.69      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewText', 'verified'], 0.25, lem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewText', 'verified'], 'proc': 'lem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ad149e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.78      0.78      1284\n",
      "           0       0.71      0.69      0.70      1225\n",
      "           1       0.85      0.88      0.86      1241\n",
      "\n",
      "    accuracy                           0.78      3750\n",
      "   macro avg       0.78      0.78      0.78      3750\n",
      "weighted avg       0.78      0.78      0.78      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, None, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83b98ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.79      0.79      1284\n",
      "           0       0.70      0.74      0.72      1225\n",
      "           1       0.88      0.84      0.86      1241\n",
      "\n",
      "    accuracy                           0.79      3750\n",
      "   macro avg       0.79      0.79      0.79      3750\n",
      "weighted avg       0.79      0.79      0.79      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, None, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b791fd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.74      0.74      1284\n",
      "           0       0.68      0.66      0.67      1225\n",
      "           1       0.83      0.85      0.84      1241\n",
      "\n",
      "    accuracy                           0.75      3750\n",
      "   macro avg       0.75      0.75      0.75      3750\n",
      "weighted avg       0.75      0.75      0.75      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, baseline, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51a05a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.77      0.77      1284\n",
      "           0       0.69      0.72      0.71      1225\n",
      "           1       0.88      0.82      0.85      1241\n",
      "\n",
      "    accuracy                           0.77      3750\n",
      "   macro avg       0.78      0.77      0.77      3750\n",
      "weighted avg       0.78      0.77      0.77      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, baseline, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b72d4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.72      0.73      1284\n",
      "           0       0.67      0.65      0.66      1225\n",
      "           1       0.81      0.85      0.83      1241\n",
      "\n",
      "    accuracy                           0.74      3750\n",
      "   macro avg       0.74      0.74      0.74      3750\n",
      "weighted avg       0.74      0.74      0.74      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, stem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aec5a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.75      0.76      1284\n",
      "           0       0.68      0.72      0.70      1225\n",
      "           1       0.86      0.82      0.84      1241\n",
      "\n",
      "    accuracy                           0.76      3750\n",
      "   macro avg       0.77      0.76      0.77      3750\n",
      "weighted avg       0.77      0.76      0.77      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, stem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6cce9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.73      0.74      1284\n",
      "           0       0.67      0.68      0.68      1225\n",
      "           1       0.83      0.83      0.83      1241\n",
      "\n",
      "    accuracy                           0.75      3750\n",
      "   macro avg       0.75      0.75      0.75      3750\n",
      "weighted avg       0.75      0.75      0.75      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, lem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce2e0edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.77      0.76      1284\n",
      "           0       0.69      0.71      0.70      1225\n",
      "           1       0.87      0.82      0.84      1241\n",
      "\n",
      "    accuracy                           0.77      3750\n",
      "   macro avg       0.77      0.77      0.77      3750\n",
      "weighted avg       0.77      0.77      0.77      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary'], 0.25, lem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44263ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.79      0.79      1284\n",
      "           0       0.72      0.70      0.71      1225\n",
      "           1       0.86      0.87      0.86      1241\n",
      "\n",
      "    accuracy                           0.79      3750\n",
      "   macro avg       0.79      0.79      0.79      3750\n",
      "weighted avg       0.79      0.79      0.79      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, None, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': None, 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "316818e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.79      0.79      1284\n",
      "           0       0.71      0.72      0.71      1225\n",
      "           1       0.88      0.85      0.86      1241\n",
      "\n",
      "    accuracy                           0.79      3750\n",
      "   macro avg       0.79      0.79      0.79      3750\n",
      "weighted avg       0.79      0.79      0.79      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, None, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': None, 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67203d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.75      0.74      1284\n",
      "           0       0.69      0.66      0.67      1225\n",
      "           1       0.83      0.85      0.84      1241\n",
      "\n",
      "    accuracy                           0.75      3750\n",
      "   macro avg       0.75      0.75      0.75      3750\n",
      "weighted avg       0.75      0.75      0.75      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, baseline, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'baseline', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91024b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.77      0.76      1284\n",
      "           0       0.69      0.71      0.70      1225\n",
      "           1       0.86      0.84      0.85      1241\n",
      "\n",
      "    accuracy                           0.77      3750\n",
      "   macro avg       0.77      0.77      0.77      3750\n",
      "weighted avg       0.77      0.77      0.77      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, baseline, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'baseline', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e573e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.73      0.73      1284\n",
      "           0       0.67      0.65      0.66      1225\n",
      "           1       0.81      0.85      0.83      1241\n",
      "\n",
      "    accuracy                           0.74      3750\n",
      "   macro avg       0.74      0.74      0.74      3750\n",
      "weighted avg       0.74      0.74      0.74      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, stem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'stem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e46adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.75      0.75      1284\n",
      "           0       0.68      0.69      0.69      1225\n",
      "           1       0.85      0.83      0.84      1241\n",
      "\n",
      "    accuracy                           0.76      3750\n",
      "   macro avg       0.76      0.76      0.76      3750\n",
      "weighted avg       0.76      0.76      0.76      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, stem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'stem', 'vectorizer': 'tfidf'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2edece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.73      0.73      1284\n",
      "           0       0.67      0.68      0.67      1225\n",
      "           1       0.83      0.83      0.83      1241\n",
      "\n",
      "    accuracy                           0.75      3750\n",
      "   macro avg       0.75      0.75      0.75      3750\n",
      "weighted avg       0.75      0.75      0.75      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, lem, bow, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'lem', 'vectorizer': 'bow'}, grid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc28e029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.76      0.76      1284\n",
      "           0       0.69      0.70      0.69      1225\n",
      "           1       0.86      0.83      0.84      1241\n",
      "\n",
      "    accuracy                           0.77      3750\n",
      "   macro avg       0.77      0.76      0.77      3750\n",
      "weighted avg       0.77      0.77      0.77      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = pipeline(['reviewTextWithSummary', 'verified'], 0.25, lem, tfidf, df_testing)\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=verbose, n_jobs=n_jobs, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "grid_score = grid.score(x_test, y_test)\n",
    "compare_list.loc[len(compare_list)] = [grid.best_params_, {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'lem', 'vectorizer': 'tfidf'}, grid_score]\n",
    "#######  END OF GENERATED CODE  #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "970d6740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid Params</th>\n",
       "      <th>Data config and preprocessing</th>\n",
       "      <th>Grid Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': None, 'vectorizer': 'bow'}</td>\n",
       "      <td>0.787467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': None, 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'bow'}</td>\n",
       "      <td>0.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': 'baseline', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.770133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.767733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': 'lem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.765067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.764267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': 'stem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.760800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': 'baseline', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.752267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.747200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': 'lem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.746133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary', 'verified'], 'proc': 'stem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.741600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>{'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.741333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': None, 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': None, 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.723733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': 'baseline', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.700533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': None, 'vectorizer': 'bow'}</td>\n",
       "      <td>0.698667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': None, 'vectorizer': 'bow'}</td>\n",
       "      <td>0.696800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': 'baseline', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.694933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': 'lem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.693067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': 'stem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.691467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': 'lem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': 'stem', 'vectorizer': 'tfidf'}</td>\n",
       "      <td>0.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': 'baseline', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': 'stem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.674667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': 'stem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.672267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': 'baseline', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.671733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText', 'verified'], 'proc': 'lem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.666933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'col': ['reviewText'], 'proc': 'lem', 'vectorizer': 'bow'}</td>\n",
       "      <td>0.663467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Grid Params  \\\n",
       "0           {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "1      {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "2          {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "3    {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "4           {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "5          {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "6           {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "7          {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "8           {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "9          {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "10     {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "11     {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "12      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "13      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "14     {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "15     {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "16          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "17          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "18          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "19     {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "20     {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "21          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "22          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "23          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "24          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "25          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "26      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "27      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "28      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "29    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "30      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "31  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "\n",
       "                                                                Data config and preprocessing  \\\n",
       "0                     {'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'tfidf'}   \n",
       "1           {'col': ['reviewTextWithSummary', 'verified'], 'proc': None, 'vectorizer': 'bow'}   \n",
       "2         {'col': ['reviewTextWithSummary', 'verified'], 'proc': None, 'vectorizer': 'tfidf'}   \n",
       "3                       {'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'bow'}   \n",
       "4               {'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'tfidf'}   \n",
       "5   {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'baseline', 'vectorizer': 'tfidf'}   \n",
       "6                    {'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'tfidf'}   \n",
       "7        {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'lem', 'vectorizer': 'tfidf'}   \n",
       "8                   {'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'tfidf'}   \n",
       "9       {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'stem', 'vectorizer': 'tfidf'}   \n",
       "10    {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'baseline', 'vectorizer': 'bow'}   \n",
       "11                {'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'bow'}   \n",
       "12                     {'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'bow'}   \n",
       "13         {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'lem', 'vectorizer': 'bow'}   \n",
       "14        {'col': ['reviewTextWithSummary', 'verified'], 'proc': 'stem', 'vectorizer': 'bow'}   \n",
       "15                    {'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'bow'}   \n",
       "16                               {'col': ['reviewText'], 'proc': None, 'vectorizer': 'tfidf'}   \n",
       "17                   {'col': ['reviewText', 'verified'], 'proc': None, 'vectorizer': 'tfidf'}   \n",
       "18                         {'col': ['reviewText'], 'proc': 'baseline', 'vectorizer': 'tfidf'}   \n",
       "19                     {'col': ['reviewText', 'verified'], 'proc': None, 'vectorizer': 'bow'}   \n",
       "20                                 {'col': ['reviewText'], 'proc': None, 'vectorizer': 'bow'}   \n",
       "21             {'col': ['reviewText', 'verified'], 'proc': 'baseline', 'vectorizer': 'tfidf'}   \n",
       "22                              {'col': ['reviewText'], 'proc': 'lem', 'vectorizer': 'tfidf'}   \n",
       "23                             {'col': ['reviewText'], 'proc': 'stem', 'vectorizer': 'tfidf'}   \n",
       "24                  {'col': ['reviewText', 'verified'], 'proc': 'lem', 'vectorizer': 'tfidf'}   \n",
       "25                 {'col': ['reviewText', 'verified'], 'proc': 'stem', 'vectorizer': 'tfidf'}   \n",
       "26               {'col': ['reviewText', 'verified'], 'proc': 'baseline', 'vectorizer': 'bow'}   \n",
       "27                   {'col': ['reviewText', 'verified'], 'proc': 'stem', 'vectorizer': 'bow'}   \n",
       "28                               {'col': ['reviewText'], 'proc': 'stem', 'vectorizer': 'bow'}   \n",
       "29                           {'col': ['reviewText'], 'proc': 'baseline', 'vectorizer': 'bow'}   \n",
       "30                    {'col': ['reviewText', 'verified'], 'proc': 'lem', 'vectorizer': 'bow'}   \n",
       "31                                {'col': ['reviewText'], 'proc': 'lem', 'vectorizer': 'bow'}   \n",
       "\n",
       "    Grid Score  \n",
       "0     0.789600  \n",
       "1     0.787467  \n",
       "2     0.787200  \n",
       "3     0.781600  \n",
       "4     0.772800  \n",
       "5     0.770133  \n",
       "6     0.767733  \n",
       "7     0.765067  \n",
       "8     0.764267  \n",
       "9     0.760800  \n",
       "10    0.753333  \n",
       "11    0.752267  \n",
       "12    0.747200  \n",
       "13    0.746133  \n",
       "14    0.741600  \n",
       "15    0.741333  \n",
       "16    0.724800  \n",
       "17    0.723733  \n",
       "18    0.700533  \n",
       "19    0.698667  \n",
       "20    0.696800  \n",
       "21    0.694933  \n",
       "22    0.693067  \n",
       "23    0.691467  \n",
       "24    0.690400  \n",
       "25    0.690400  \n",
       "26    0.677600  \n",
       "27    0.674667  \n",
       "28    0.672267  \n",
       "29    0.671733  \n",
       "30    0.666933  \n",
       "31    0.663467  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "compare_list = compare_list.sort_values(by=\"Grid Score\", ascending=False).reset_index(drop=True)\n",
    "display(compare_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d17f19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration on testing dataset (size=15000):\n",
      "Score ::  0.7896\n",
      "SVC   ::  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "data  ::  {'col': ['reviewTextWithSummary'], 'proc': None, 'vectorizer': 'tfidf'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Configuration on testing dataset (size={len(df_testing)}):\")\n",
    "print(\"Score :: \", compare_list.loc[0][\"Grid Score\"])\n",
    "print(\"SVC   :: \", compare_list.loc[0][\"Grid Params\"])\n",
    "print(\"data  :: \", compare_list.loc[0][\"Data config and preprocessing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539395e9",
   "metadata": {},
   "source": [
    "- Across all tests, reviewText with summary performed better than reviewText without summary.\n",
    "- The RBF kernel performed better than the linear kernel in almost all cases.\n",
    "- The top configuration was as follows:\n",
    "  - Data::\n",
    "    - Columns used: reviewTextWithSummary\n",
    "    - Text preprocessing step: None\n",
    "    - Text vectorizer: tfidf\n",
    "  - SVC::\n",
    "    - C=1\n",
    "    - gamma=1\n",
    "    - kernel=rbf\n",
    "\n",
    "Using these parameters, lets build a model on a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140870c",
   "metadata": {},
   "source": [
    "## Building larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "470ad34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = (\n",
    "    df.groupby(\"sentiment\")\n",
    "    .apply(lambda x: x.sample(n=large_n, random_state=random_state, replace=True))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "996cec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    \"I loved this product, it was amazing\",\n",
    "    \"I hated this product, it was terrible\",\n",
    "    \"This product was okay, it was fine\",\n",
    "    \"I am not sure how I feel about this product\",\n",
    "    \"Apple really outdid themselves with this product\",\n",
    "    \"The engine was really loud, but otherwise the car was fine\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188b4d7",
   "metadata": {},
   "source": [
    "### Top performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "813617bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_large[[\"reviewTextWithSummary\"]],\n",
    "    df_large[\"sentiment\"],\n",
    "    test_size=0.25,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73b8490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_testing_top_config = TfidfVectorizer()\n",
    "x_train = vec_testing_top_config.fit_transform(x_train[\"reviewTextWithSummary\"])\n",
    "x_test = vec_testing_top_config.transform(x_test[\"reviewTextWithSummary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8197e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_testing_top_config = SVC(C=1, gamma=1, kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1fe85a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_testing_top_config.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74da9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_testing_top_config.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09168117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = [vec_testing_top_config.transform([x]) for x in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a5cdae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this product, it was amazing\n",
      "[1]\n",
      "\n",
      "I hated this product, it was terrible\n",
      "[-1]\n",
      "\n",
      "This product was okay, it was fine\n",
      "[0]\n",
      "\n",
      "I am not sure how I feel about this product\n",
      "[-1]\n",
      "\n",
      "Apple really outdid themselves with this product\n",
      "[-1]\n",
      "\n",
      "The engine was really loud, but otherwise the car was fine\n",
      "[0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, p in zip(sample, sample_):\n",
    "    print(s)\n",
    "    print(svc_testing_top_config.predict(p))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbdf4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.90      0.90     12448\n",
      "           0       0.84      0.87      0.86     12571\n",
      "           1       0.93      0.89      0.91     12481\n",
      "\n",
      "    accuracy                           0.89     37500\n",
      "   macro avg       0.89      0.89      0.89     37500\n",
      "weighted avg       0.89      0.89      0.89     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364636d5",
   "metadata": {},
   "source": [
    "- Results seem very good with an F1 Score of 0.87\n",
    "- Interestingly, the top perfomring model did not use any text preprocessing\n",
    "- The next best performing models that used different text preprocessing were as follows:\n",
    "  - baseline text preprocessing with tfidf vectorizer: score of 0.7728\n",
    "  - lemmatized text preprocessing with tfidf vectorizer: score of 0.7677\n",
    "  - stemmed text preprocessing with tfidf vectorizer: score of 0.7642\n",
    "- These results are within 2% than the selected model, so it may be worth exploring these models further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d26e3",
   "metadata": {},
   "source": [
    "### Baseline with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e79adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration using baseline text preprocessing\n",
      "Score ::  0.7728\n",
      "SVC   ::  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "data  ::  {'col': ['reviewTextWithSummary'], 'proc': 'baseline', 'vectorizer': 'tfidf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best configuration using baseline text preprocessing\")\n",
    "print(\"Score :: \", compare_list.loc[4][\"Grid Score\"])\n",
    "print(\"SVC   :: \", compare_list.loc[4][\"Grid Params\"])\n",
    "print(\"data  :: \", compare_list.loc[4][\"Data config and preprocessing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51f03149",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_large[[\"reviewTextWithSummary\"]],\n",
    "    df_large[\"sentiment\"],\n",
    "    test_size=0.25,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f137d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"reviewTextWithSummary\"] = x_train[\"reviewTextWithSummary\"].apply(\n",
    "    lambda x: preprocess_text(x, STOP_WORDS, baseline)\n",
    ")\n",
    "x_test[\"reviewTextWithSummary\"] = x_test[\"reviewTextWithSummary\"].apply(\n",
    "    lambda x: preprocess_text(x, STOP_WORDS, baseline)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2f4966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_baseline_tfidf = TfidfVectorizer()\n",
    "x_train = vec_baseline_tfidf.fit_transform(x_train[\"reviewTextWithSummary\"])\n",
    "x_test = vec_baseline_tfidf.transform(x_test[\"reviewTextWithSummary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69596b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_baseline_tfidf = SVC(C=1, gamma=1, kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b1241dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_baseline_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d9876d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_baseline_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "370dd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = [preprocess_text(x, STOP_WORDS, baseline) for x in sample]\n",
    "sample_ = [vec_baseline_tfidf.transform([x]) for x in sample_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd12e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this product, it was amazing\n",
      "[1]\n",
      "\n",
      "I hated this product, it was terrible\n",
      "[-1]\n",
      "\n",
      "This product was okay, it was fine\n",
      "[0]\n",
      "\n",
      "I am not sure how I feel about this product\n",
      "[-1]\n",
      "\n",
      "Apple really outdid themselves with this product\n",
      "[-1]\n",
      "\n",
      "The engine was really loud, but otherwise the car was fine\n",
      "[0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, p in zip(sample, sample_):\n",
    "    print(s)\n",
    "    print(svc_baseline_tfidf.predict(p))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6595cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.90      0.89     12448\n",
      "           0       0.84      0.85      0.85     12571\n",
      "           1       0.92      0.89      0.90     12481\n",
      "\n",
      "    accuracy                           0.88     37500\n",
      "   macro avg       0.88      0.88      0.88     37500\n",
      "weighted avg       0.88      0.88      0.88     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c746d",
   "metadata": {},
   "source": [
    "### Lemmatized with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a0b9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration using baseline text preprocessing\n",
      "Score ::  0.7677333333333334\n",
      "SVC   ::  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "data  ::  {'col': ['reviewTextWithSummary'], 'proc': 'lem', 'vectorizer': 'tfidf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best configuration using baseline text preprocessing\")\n",
    "print(\"Score :: \", compare_list.loc[6][\"Grid Score\"])\n",
    "print(\"SVC   :: \", compare_list.loc[6][\"Grid Params\"])\n",
    "print(\"data  :: \", compare_list.loc[6][\"Data config and preprocessing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07ce5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_large[[\"reviewTextWithSummary\"]],\n",
    "    df_large[\"sentiment\"],\n",
    "    test_size=0.25,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f9c141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"reviewTextWithSummary\"] = x_train[\"reviewTextWithSummary\"].apply(\n",
    "    lambda x: preprocess_text(x, STOP_WORDS, lem)\n",
    ")\n",
    "x_test[\"reviewTextWithSummary\"] = x_test[\"reviewTextWithSummary\"].apply(\n",
    "    lambda x: preprocess_text(x, STOP_WORDS, lem)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "200b504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_lematized_tfidf = TfidfVectorizer()\n",
    "x_train = vec_lematized_tfidf.fit_transform(x_train[\"reviewTextWithSummary\"])\n",
    "x_test = vec_lematized_tfidf.transform(x_test[\"reviewTextWithSummary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66450bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_lematized_tfidf = SVC(C=1, gamma=1, kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8a748ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lematized_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cfd3ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_lematized_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9ca68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = [preprocess_text(x, STOP_WORDS, lem) for x in sample]\n",
    "sample_ = [vec_lematized_tfidf.transform([x]) for x in sample_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b4cd921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this product, it was amazing\n",
      "[1]\n",
      "\n",
      "I hated this product, it was terrible\n",
      "[-1]\n",
      "\n",
      "This product was okay, it was fine\n",
      "[0]\n",
      "\n",
      "I am not sure how I feel about this product\n",
      "[-1]\n",
      "\n",
      "Apple really outdid themselves with this product\n",
      "[-1]\n",
      "\n",
      "The engine was really loud, but otherwise the car was fine\n",
      "[0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, p in zip(sample, sample_):\n",
    "    print(s)\n",
    "    print(svc_lematized_tfidf.predict(p))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0d83d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.90      0.89     12448\n",
      "           0       0.84      0.85      0.84     12571\n",
      "           1       0.92      0.88      0.90     12481\n",
      "\n",
      "    accuracy                           0.88     37500\n",
      "   macro avg       0.88      0.88      0.88     37500\n",
      "weighted avg       0.88      0.88      0.88     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac2ea9",
   "metadata": {},
   "source": [
    "### Stemmed with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e6334b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration using baseline text preprocessing\n",
      "Score ::  0.7642666666666666\n",
      "SVC   ::  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "data  ::  {'col': ['reviewTextWithSummary'], 'proc': 'stem', 'vectorizer': 'tfidf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best configuration using baseline text preprocessing\")\n",
    "print(\"Score :: \", compare_list.loc[8][\"Grid Score\"])\n",
    "print(\"SVC   :: \", compare_list.loc[8][\"Grid Params\"])\n",
    "print(\"data  :: \", compare_list.loc[8][\"Data config and preprocessing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2dcf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_large[[\"reviewTextWithSummary\"]],\n",
    "    df_large[\"sentiment\"],\n",
    "    test_size=0.25,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0064141",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"reviewTextWithSummary\"] = x_train[\"reviewTextWithSummary\"].apply(\n",
    "    lambda x: preprocess_text(x, STOP_WORDS, stem)\n",
    ")\n",
    "x_test[\"reviewTextWithSummary\"] = x_test[\"reviewTextWithSummary\"].apply(\n",
    "    lambda x: preprocess_text(x, STOP_WORDS, stem)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "26d9161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_stemmed_tfidf = TfidfVectorizer()\n",
    "x_train = vec_stemmed_tfidf.fit_transform(x_train[\"reviewTextWithSummary\"])\n",
    "x_test = vec_stemmed_tfidf.transform(x_test[\"reviewTextWithSummary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "174c7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_stemmed_tfidf = SVC(C=1, gamma=1, kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97446d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_stemmed_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4d58a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_stemmed_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee7fb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = [preprocess_text(x, STOP_WORDS, stem) for x in sample]\n",
    "sample_ = [vec_stemmed_tfidf.transform([x]) for x in sample_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c031d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this product, it was amazing\n",
      "[1]\n",
      "\n",
      "I hated this product, it was terrible\n",
      "[-1]\n",
      "\n",
      "This product was okay, it was fine\n",
      "[0]\n",
      "\n",
      "I am not sure how I feel about this product\n",
      "[0]\n",
      "\n",
      "Apple really outdid themselves with this product\n",
      "[-1]\n",
      "\n",
      "The engine was really loud, but otherwise the car was fine\n",
      "[0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, p in zip(sample, sample_):\n",
    "    print(s)\n",
    "    print(svc_stemmed_tfidf.predict(p))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c60eabc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.89      0.89     12448\n",
      "           0       0.84      0.85      0.84     12571\n",
      "           1       0.91      0.88      0.90     12481\n",
      "\n",
      "    accuracy                           0.88     37500\n",
      "   macro avg       0.88      0.88      0.88     37500\n",
      "weighted avg       0.88      0.88      0.88     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7357b",
   "metadata": {},
   "source": [
    "- All models perform within a percent of each other based on their own test sets\n",
    "- lets compare each of these models on the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b2e08",
   "metadata": {},
   "source": [
    "## Testing on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "51edaceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"reviewTextWithSummary\"]]\n",
    "y = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "131552a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_top_config = vec_testing_top_config.transform(x[\"reviewTextWithSummary\"])\n",
    "x_baseline_tfidf = vec_baseline_tfidf.transform(\n",
    "    x[\"reviewTextWithSummary\"].apply(lambda x: preprocess_text(x, STOP_WORDS, baseline))\n",
    ")\n",
    "x_lematized_tfidf = vec_lematized_tfidf.transform(\n",
    "    x[\"reviewTextWithSummary\"].apply(lambda x: preprocess_text(x, STOP_WORDS, lem))\n",
    ")\n",
    "x_stemmed_tfidf = vec_stemmed_tfidf.transform(\n",
    "    x[\"reviewTextWithSummary\"].apply(lambda x: preprocess_text(x, STOP_WORDS, stem))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a18874df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_top_config = svc_testing_top_config.predict(x_top_config)\n",
    "y_pred_baseline_tfidf = svc_baseline_tfidf.predict(x_baseline_tfidf)\n",
    "y_pred_lematized_tfidf = svc_lematized_tfidf.predict(x_lematized_tfidf)\n",
    "y_pred_stemmed_tfidf = svc_stemmed_tfidf.predict(x_stemmed_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b9ef1311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Config\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.90      0.77     44501\n",
      "           0       0.41      0.86      0.56     47109\n",
      "           1       0.99      0.89      0.94    657241\n",
      "\n",
      "    accuracy                           0.89    748851\n",
      "   macro avg       0.69      0.89      0.76    748851\n",
      "weighted avg       0.94      0.89      0.91    748851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Config\")\n",
    "print(classification_report(y, y_pred_top_config))\n",
    "score_top_config = f1_score(y, y_pred_top_config, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b98b8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.90      0.73     44501\n",
      "           0       0.41      0.85      0.55     47109\n",
      "           1       0.99      0.89      0.94    657241\n",
      "\n",
      "    accuracy                           0.88    748851\n",
      "   macro avg       0.67      0.88      0.74    748851\n",
      "weighted avg       0.93      0.88      0.90    748851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline with tfidf\")\n",
    "print(classification_report(y, y_pred_baseline_tfidf))\n",
    "score_baseline_tfidf = f1_score(y, y_pred_baseline_tfidf, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3114f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lematized with tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.89      0.72     44501\n",
      "           0       0.41      0.85      0.55     47109\n",
      "           1       0.99      0.88      0.94    657241\n",
      "\n",
      "    accuracy                           0.88    748851\n",
      "   macro avg       0.67      0.88      0.74    748851\n",
      "weighted avg       0.93      0.88      0.90    748851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Lematized with tfidf\")\n",
    "print(classification_report(y, y_pred_lematized_tfidf))\n",
    "score_lematized_tfidf = f1_score(y, y_pred_lematized_tfidf, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46c82de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed with tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.89      0.72     44501\n",
      "           0       0.40      0.85      0.54     47109\n",
      "           1       0.99      0.88      0.93    657241\n",
      "\n",
      "    accuracy                           0.88    748851\n",
      "   macro avg       0.66      0.87      0.73    748851\n",
      "weighted avg       0.93      0.88      0.90    748851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Stemmed with tfidf\")\n",
    "print(classification_report(y, y_pred_stemmed_tfidf))\n",
    "score_stemmed_tfidf = f1_score(y, y_pred_stemmed_tfidf, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47e97db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "Overall top config (No preprocessing) ::  0.9067389973023244\n",
      "Baseline preprocessing top config     ::  0.8998075765013855\n",
      "Lemmatized preprocessing top config   ::  0.8983562736247437\n",
      "Stemmed preprocessing top config      ::  0.8963572243555369\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores\")\n",
    "print(\"Overall top config (No preprocessing) :: \", score_top_config)\n",
    "print(\"Baseline preprocessing top config     :: \", score_baseline_tfidf)\n",
    "print(\"Lemmatized preprocessing top config   :: \", score_lematized_tfidf)\n",
    "print(\"Stemmed preprocessing top config      :: \", score_stemmed_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0a6a7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Performance ranking is the same as the experimental results from before\n",
    "- All selected models perform at a very high level, all around 88% accurate with F1 scores around 0.9\n",
    "- The overall top performing model was the one that did not use any text preprocessing with the following:\n",
    "  - Text was not preprocessesed\n",
    "  - Text was vectorized using the tfidf vectorizer\n",
    "  - SVC with C=1, gamma=1, kernel=rbf\n",
    "  - Weighted F1 score = 0.9067"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
